# PD3QN: A Predictive Dueling Double Deep Q-Network
# åŸºäºè½»é‡çº§æœªæ¥çŠ¶æ€é¢„æµ‹ä¸è‡ªé€‚åº”ç½®ä¿¡åº¦é—¨æ§çš„é¢„æµ‹å‹ D3QN

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

è¿™æ˜¯è®ºæ–‡ **"PD3QN: A Predictive Dueling Double Deep Q-Network with Lightweight Future State Prediction and Adaptive Confidence Gating"** çš„å®˜æ–¹ä»£ç å®ç°ã€‚

PD3QN æ˜¯ä¸€ç§æ–°é¢–çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDRLï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³é«˜åŠ¨æ€ã€ä½å®¹é”™ç¯å¢ƒï¼ˆå¦‚ **å¸¦ç«çƒçš„ Flappy Bird**ï¼‰ä¸­çš„**å†³ç­–çŸ­è§†ï¼ˆDecision Myopiaï¼‰**é—®é¢˜ã€‚é€šè¿‡å°†è½»é‡çº§ç¯å¢ƒæ¨¡å‹ä¸ Model-free éª¨å¹²ç½‘ç»œç»“åˆï¼Œå®ç°äº†é²æ£’çš„é•¿ç¨‹è§„åˆ’èƒ½åŠ›ã€‚

## ğŸ“– ç›®å½•
- [èƒŒæ™¯ä»‹ç»](#-èƒŒæ™¯ä»‹ç»)
- [æ ¸å¿ƒç‰¹æ€§](#-æ ¸å¿ƒç‰¹æ€§)
- [ç›®å½•ç»“æ„](#-ç›®å½•ç»“æ„)
- [ç¯å¢ƒå®‰è£…](#-ç¯å¢ƒå®‰è£…)
- [ä½¿ç”¨æŒ‡å—](#-ä½¿ç”¨æŒ‡å—)
  - [è®­ç»ƒæ¨¡å‹](#è®­ç»ƒæ¨¡å‹)
  - [æµ‹è¯•æ¨¡å‹](#æµ‹è¯•æ¨¡å‹)
  - [ç›‘æ§è®­ç»ƒ](#ç›‘æ§è®­ç»ƒ)
- [ç¯å¢ƒè¯´æ˜](#-ç¯å¢ƒè¯´æ˜)
- [è‡´è°¢](#-è‡´è°¢)

## ğŸ§© èƒŒæ™¯ä»‹ç»

ä¼ ç»Ÿçš„ Model-free ç®—æ³•ï¼ˆå¦‚ D3QNï¼‰åœ¨é¢å¯¹å¿«èŠ‚å¥ç¯å¢ƒæ—¶å¾€å¾€ç¼ºä¹å‰ç»æ€§ã€‚PD3QN é€šè¿‡å¼•å…¥ä»¥ä¸‹æœºåˆ¶è§£å†³äº†è¿™ä¸€é—®é¢˜ï¼š

1.  **ä¸€æ­¥çŠ¶æ€é¢„æµ‹å™¨ (OSSP):** ä¸€ä¸ªè½»é‡çº§æ¨¡å—ï¼Œç”¨äºé¢„æµ‹ä¸‹ä¸€å¸§ç”»é¢åŠæ­»äº¡é£é™©ã€‚
2.  **è‡ªé€‚åº”ç½®ä¿¡åº¦é—¨æ§ (CGN):** åŠ¨æ€è°ƒèŠ‚å¯¹é¢„æµ‹ç»“æœçš„ä¿¡ä»»ç¨‹åº¦ï¼Œé˜²æ­¢æ—©æœŸæ¨¡å‹è¯¯å·®è¯¯å¯¼ç­–ç•¥å­¦ä¹ ã€‚
3.  **å›ºå®šåŠ¨ä½œå‘é‡ (Fixed Action Vectors):** æ›¿ä»£ä¼ ç»Ÿçš„å¯å­¦ä¹  Embeddingï¼Œåœ¨è®­ç»ƒåˆæœŸæä¾›ç¨³å®šçš„è¾“å…¥ç‰¹å¾ã€‚

<p align="center">
  <img src="assets/framework.png" alt="PD3QN Framework" width="800">
  <br>
  <em>å›¾ï¼šPD3QN æ•´ä½“æ¶æ„å›¾ï¼ˆè¯·ç¡®ä¿ assets ç›®å½•ä¸‹æœ‰ framework.pngï¼‰</em>
</p>

## âœ¨ æ ¸å¿ƒç‰¹æ€§

* **æ··åˆæŸå¤±å‡½æ•° (Hybrid Loss):** ç»“åˆ MSEã€è¾¹ç¼˜æ£€æµ‹ (Sobel) å’Œ SSIMï¼Œå¼ºåˆ¶é¢„æµ‹å™¨å…³æ³¨ç‰©ç†ç»“æ„è€ŒéèƒŒæ™¯å™ªå£°ã€‚
* **åˆ†å±‚ç»éªŒå›æ”¾ (Stratified Experience Replay):** å¹³è¡¡æ¸¸æˆæ—©æœŸï¼ˆç®€å•åœºæ™¯ï¼‰å’Œæ™šæœŸï¼ˆå¤æ‚åœºæ™¯ï¼‰çš„æ ·æœ¬åˆ†å¸ƒï¼Œé˜²æ­¢é—å¿˜ã€‚
* **å¯†é›†å¼•å¯¼å¥–åŠ± (Dense Guided Rewards):** åˆ©ç”¨åŸºäºè·ç¦»çš„å¥–åŠ±å¡‘å½¢ï¼Œæ˜¾è‘—åŠ é€Ÿè®­ç»ƒæ”¶æ•›ã€‚
* **é«˜éš¾åº¦ç¯å¢ƒ:** åœ¨åŸç‰ˆ Flappy Bird åŸºç¡€ä¸Šå¢åŠ äº†**åŠ¨æ€ç«çƒ**éšœç¢ï¼Œè€ƒéªŒæ™ºèƒ½ä½“çš„åŠ¨æ€é¿éšœèƒ½åŠ›ã€‚

## ğŸ“‚ ç›®å½•ç»“æ„

åŸºäºæœ¬ä»“åº“çš„ä»£ç ç»„ç»‡ï¼š

```text
PD3QN/
â”œâ”€â”€ assets/                          # æ¸¸æˆèµ„æº (å›¾ç‰‡ sprites, å­—ä½“ fonts)
â”œâ”€â”€ DDQN_Innovation_Research/
â”‚   â””â”€â”€ improvements/
â”‚       â””â”€â”€ experiments/
â”‚           â””â”€â”€ train_PD3QN.py       # ğŸš€ æ ¸å¿ƒè®­ç»ƒè„šæœ¬
â”œâ”€â”€ logs/                            # TensorBoard æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ results/                         # æ¨¡å‹ä¿å­˜ (.pth) å’Œæµ‹è¯•æŠ¥å‘Š (.json)
â”œâ”€â”€ src/                             # æºä»£ç åº“
â”‚   â”œâ”€â”€ flappy_bird.py               # æ¸¸æˆç¯å¢ƒ (è®­ç»ƒç‰ˆ)
â”‚   â”œâ”€â”€ flappy_bird-test.py          # æ¸¸æˆç¯å¢ƒ (æµ‹è¯•ç‰ˆ - æ— å¤´æ¨¡å¼é€‚é…)
â”‚   â””â”€â”€ requirements.txt             # é¡¹ç›®ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ test_PD3QN.py                    # ğŸ§ª æ‰¹é‡æµ‹è¯•è„šæœ¬
â””â”€â”€ README.md                        # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## âš™ï¸ ç¯å¢ƒå®‰è£…

1. **å…‹éš†ä»“åº“:**

   ```bash
   git clone [https://github.com/your-username/PD3QN.git](https://github.com/your-username/PD3QN.git)
   cd PD3QN
   ```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è):**

   ```bash
   conda create -n pd3qn python=3.10
   conda activate pd3qn
   ```

3. **å®‰è£…ä¾èµ–:**
   æ³¨æ„ï¼š`requirements.txt` ä½äº `src` ç›®å½•ä¸‹ã€‚

   ```bash
   pip install -r src/requirements.txt
   ```
   *ä¸»è¦ä¾èµ–åŒ…æ‹¬: `torch`, `pygame`, `opencv-python`, `tensorboardX`, `numpy` ç­‰ã€‚*

## ğŸš€ ä½¿ç”¨æŒ‡å—

### è®­ç»ƒæ¨¡å‹
ä»å¤´å¼€å§‹è®­ç»ƒ PD3QN æ¨¡å‹ã€‚è„šæœ¬ä½¿ç”¨ `StratifiedExperienceBuffer` å’Œ `FixedActionVectors`ã€‚

ç”±äºè„šæœ¬è·¯å¾„è¾ƒæ·±ï¼Œè¯·åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œï¼š

```bash
python DDQN_Innovation_Research/improvements/experiments/train_PD3QN.py
```

* **é…ç½®:** æ‚¨å¯ä»¥åœ¨ `train_PD3QN.py` ä¸­ç›´æ¥ä¿®æ”¹è¶…å‚æ•°ï¼ˆBatch size, LR, Gamma ç­‰ï¼‰ã€‚
* **æ—¥å¿—:** è®­ç»ƒæ—¥å¿—å°†ä¿å­˜è‡³ `logs/PD3QN_FixedVectors/`ã€‚
* **æ¨¡å‹:** æ£€æŸ¥ç‚¹ï¼ˆCheckpointsï¼‰å°†ä¿å­˜è‡³ `results/PD3QN_FixedVectors/`ã€‚

### æµ‹è¯•æ¨¡å‹
ç”¨äºè¯„ä¼°å·²è®­ç»ƒçš„æ¨¡å‹ã€‚è¯¥è„šæœ¬ä¼šæ‰§è¡Œæ‰¹é‡æµ‹è¯•ï¼Œè®¡ç®—ä¿®å‰ªåçš„å¹³å‡åˆ†ï¼ˆå»é™¤æœ€é«˜/æœ€ä½åˆ†ï¼‰ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šã€‚

```bash
python test_PD3QN.py
```

* è„šæœ¬ä¼šè‡ªåŠ¨æœç´¢ `results/PD3QN_FixedVectors/` ç›®å½•ä¸‹çš„æ¨¡å‹æ–‡ä»¶ã€‚
* æµ‹è¯•æ‘˜è¦å’Œè¯¦ç»† JSON æŠ¥å‘Šå°†ç”Ÿæˆåœ¨ `results/test_reports/` ä¸­ã€‚

### ç›‘æ§è®­ç»ƒ
ä½¿ç”¨ TensorBoard å®æ—¶æŸ¥çœ‹ Loss å’Œ Qå€¼æ›²çº¿ï¼š

```bash
tensorboard --logdir=logs/PD3QN_FixedVectors
```

## ğŸ® ç¯å¢ƒè¯´æ˜: Flappy Bird with Fireballs

æœ¬ç¯å¢ƒæ˜¯åŸºäº `pygame` ä¿®æ”¹çš„é«˜éš¾åº¦ç‰ˆæœ¬ï¼š

* **çŠ¶æ€ (State):** è¿ç»­ 4 å¸§å †å çš„ç°åº¦å›¾åƒ (84x84)ã€‚
* **åŠ¨ä½œ (Actions):** 0 (ä»€ä¹ˆéƒ½ä¸åš), 1 (è·³è·ƒ/Flap)ã€‚
* **å¥–åŠ± (Rewards):**
    * å­˜æ´»æ¯å¸§: +0.1
    * é€šè¿‡ç®¡é“: +1.0
    * èº²é¿ç«çƒ: +0.5
    * ç¢°æ’ (Terminal): -1.0
    * *å¯†é›†å¼•å¯¼:* åŸºäºä¸ç®¡é“ä¸­å¿ƒè·ç¦»çš„è¿ç»­å¥–åŠ±/æƒ©ç½šã€‚



## ğŸ¤ è‡´è°¢ (Acknowledgments)

* **ä»£ç è‡´è°¢ (Code Reference):**
    æœ¬é¡¹ç›®çš„æ¸¸æˆç¯å¢ƒä»£ç å‚è€ƒå¹¶ä¿®æ”¹è‡ª [SeVEnMY/ReinforcementLearningFlappyBird](https://github.com/SeVEnMY/ReinforcementLearningFlappyBird)ã€‚
   

* **åŸºé‡‘æ”¯æŒ (Funding):**
    æœ¬ç ”ç©¶å·¥ä½œå¾—åˆ°äº†ä»¥ä¸‹é¡¹ç›®çš„èµ„åŠ©ï¼š
    * **National Natural Science Foundation of China** (Grant No. 62471272, 61806107, 62201314)
    * **Opening Project of State Key Laboratory of Digital Publishing Technology**
    * **NSF of Shandong Province** (Grant No. ZR2025MS986)


